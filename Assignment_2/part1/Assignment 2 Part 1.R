### Financial Engineering ####
# Assignment Part 2a: volatility modeling with SV and indirect inference
# Daniel van Hanswijk(2726843)
# Mark de Kwaasteniet(2649271)
# Martijn van Welsenes(2713315)
# Sem Wierdsma(2670919)
##############################

#setwd("~/Documents/Documents/Bedrijfskunde jaar 3/Financial Econometrics/Assignment 2")

# Workspace preparations
# Clean workspace
rm(list=ls())    

# Load packages and/or functions
library(quantmod)
library(quadprog)
library(moments)
source("sim_m_SV.R")
source("sim_m_SV2.R")
source("sim_m_SV3.R")
source("filter_SV.R")
source("llik_fun_GARCH.R") 
source("Hess_fun_GARCH.R")

# Load data
p_SP500 <- scan("SeP500.txt")

ret_log_SP500 <- diff(log(p_SP500))*100
x <- ret_log_SP500

x_2 <- ret_log_SP500^2

par(mfrow=c(2,1),mar=c(4.1,4.1,1.1,2.1)) 
acf(x_2,main="")
title("ACF squared log-returns IBM", line = 0.3)
pacf(x_2, main="")
title("PACF squared log-returns IBM", line = 0.3)

### Question 1 ####
# Obtain sample moments

n <- length(x)
xa <- abs(x)
sample_m <- c(var(x), kurtosis(x), cor(xa[2:n],xa[1:(n-1)]))

# Generate errors for the simulations from the SV model

set.seed(123)
H <- 30*n
epsilon <- rnorm(H)  
eta <- rnorm(H)  
e <- cbind(epsilon,eta)

# Choose initial parameter values for the optimization

#choose the initail parameter values for the numerical optimization

b <- 0.90
sig2f <- 0.1
omega <- log(var(x))*(1-b)

par_ini <- c(omega,log(b/(1-b)),log(sig2f))

# Obtain parameter estimates

# Minimize criterion function

est <- optim(par=par_ini,fn=function(par) mean((sim_m_SV(e,par)-sample_m)^2), method = "BFGS")

# Obtain parameter estimate using the link functions

omega_hat <- est$par[1]
beta_hat <- exp(est$par[2])/(1+exp(est$par[2]))
sig2f_hat <- exp(est$par[3])

theta_hat <- c(omega_hat,beta_hat,sig2f_hat)
cat("The parameter estimates are:")
round(theta_hat,4)

# The omega is 0.064, the beta is 0.9365 and the value of the variance of eta is 0.1857.
# Beta is bigger than zero, therefore it is likely that the f_t+1 will be large and thus the volatility of y_t+1 will be large.

### Question 2 ####
# Obtain filtered volatility

f <- rep(0,n)
f[1] <- log(var(x))

#Run a for loop minizing the function filter_SV() at each time period to
#obtain the filtered estimate of ft 

for(t in 2:n){ # start recursion from t=2 to t=T
  ft_ini <- f[t-1]
  f_est <- optim(par=ft_ini ,fn= function(ft) filter_SV(x[t],ft,f[t-1],theta_hat), method = "BFGS")
  f[t] <- f_est$par
}

# Plot series and etimated volatility

par(mfrow=c(2,1),mar=c(4.1,4.1,1.1,2.1))
plot(x,type="l", main="Time series",ylab="",xlab="")
grid(nx = NULL, ny = NULL, col = "lightgray", lty = "dotted")
plot(exp(f/2),type="l",col=2, main="Filtered sigmat",ylab="",xlab="")
grid(nx = NULL, ny = NULL, col = "lightgray", lty = "dotted")

# Estimate a Univariate GARCH(1,1) for S&P500 log-returns x[,1]
garch_alpha_ini <- 0.01 
garch_beta_ini <- 0.9  
garch_omega_ini <- var(x)*(1-garch_alpha_ini-garch_beta_ini) 
garch_par_ini <- c(log(garch_omega_ini),log(garch_alpha_ini/(1-garch_alpha_ini)),log(garch_beta_ini/(1-garch_beta_ini)))

est1 <- optim(par=garch_par_ini,fn=function(par)-llik_fun_GARCH(par,x), method = "BFGS")

(omega_hat1 <- exp(est1$par[1]))
(alpha_hat1 <- exp(est1$par[2])/(1+exp(est1$par[2])))
(beta_hat1 <- exp(est1$par[3])/(1+exp(est1$par[3])))

n <- length(x)
sigma2 <- rep(0,n)
sigma2[1] <- var(x)

for(t in 2:n){
  sigma2[t] = omega_hat1 + alpha_hat1*x[t-1]^2 + beta_hat1*sigma2[t-1]
}

## Plot filtered volatility

par(mfrow=c(3,1),mar=c(4.1,4.1,1.1,2.1))
plot(x,type="l", main="Log Returns of S&P 500",ylab="",xlab="")
grid(nx = NULL, ny = NULL, col = "lightgray", lty = "dotted")
plot(sigma2,type="l", main="Filtered Volatility GARCH Model",ylab="",xlab="")
grid(nx = NULL, ny = NULL, col = "lightgray", lty = "dotted")
plot(exp(f/2),type="l", main="Filtered Volatility SV Model",ylab="",xlab="")
grid(nx = NULL, ny = NULL, col = "lightgray", lty = "dotted")

Volatility_model_1 <- f

par(mfrow=c(1,1),mar=c(4.1,4.1,1.1,2.1))
plot(exp(Volatility_model_1/2),type="l",col=2, main="Filtered Volatility Model 1",ylab="",xlab="")
grid(nx = NULL, ny = NULL, col = "lightgray", lty = "dotted")

# Here we clearly see clusters of volatility in the simulated time series. 
# Whenever the log returns fluctuate, the filtered stochastic volatility is has a peak.
# The GARCH volatility shows significantly higher peaks compared to the volatility generated by the indirect inference.

### Question 3 ####
#obtain the sample mean of y_t
mean_x <- mean(xa)
# obtain the autocovariance function
acv15 <-acf(xa, lag.max = 15, type = "covariance", plot = F)$acf

sample_m2 <- c(mean_x, acv15)

set.seed(123)
H <- 30*n
epsilon <- rnorm(H)  
eta <- rnorm(H)  
e <- cbind(epsilon,eta)

b <- 0.90
sig2f <- 0.1
omega <- log(var(x))*(1-b)

par_ini <- c(omega,log(b/(1-b)),log(sig2f))

# Obtain parameter estimates

# Minimize criterion function

est <- optim(par=par_ini,fn=function(par) mean((sim_m_SV2(e,par)-sample_m2)^2), method = "BFGS")

# Obtain parameter estimate using the link functions

omega_hat <- est$par[1]
beta_hat <- exp(est$par[2])/(1+exp(est$par[2]))
sig2f_hat <- exp(est$par[3])

theta_hat <- c(omega_hat,beta_hat,sig2f_hat)
cat("The parameter estimates are:")
round(theta_hat,4)

# the omega is 0.0774, the beta is 0.9301 and the sig2f is 0.1568. These values are very similar to the model estimated with the aforementioned auxiliary statistics.
# We see that the beta has decreased slightly compared with the values before.  

### Question 4 ####

# Obtain filtered volatility

f <- rep(0,n)
f[1] <- log(var(x))

#Run a for loop minizing the function filter_SV() at each time period to
#obtain the filtered estimate of ft 

for(t in 2:n){ # start recursion from t=2 to t=T
  ft_ini <- f[t-1]
  f_est <- optim(par=ft_ini ,fn= function(ft) filter_SV(x[t],ft,f[t-1],theta_hat), method = "BFGS")
  f[t] <- f_est$par
}

# Plot series and etimated volatility

par(mfrow=c(2,1),mar=c(4.1,4.1,1.1,2.1))
plot(exp(Volatility_model_1/2),type="l", main="Filtered Volatility Model 1",ylab="",xlab="")
grid(nx = NULL, ny = NULL, col = "lightgray", lty = "dotted")
plot(exp(f/2),type="l", main="Filtered Volatility Model 2",ylab="",xlab="")
grid(nx = NULL, ny = NULL, col = "lightgray", lty = "dotted")

#Comment on the results
# The results are very similar. Using eye-ball econometrics it is not really possible to distinguish the differences.
# This is not surprising, because the parameters were very similar as well.
# ondanks dat dit niet zichtbaar is, weten we dat de beta kleiner is geworden. Dit betekent dat de stochastic volatility van de tweede lager is dan de eerste.


### Question 5 ####
# The auxilary statistics should correspond to the AR(p) parameters. 
# Therefore they should correspond to B_0, B_1, B_2 and C^2.
# Because the parameters of the ar(2) model describe the autocovariance structure of the squared log-returns. 
# Therefore, i would chose the auxilary statistics of question 3.

### Question 6 ####
#obtain the sample mean of y_t
mean_x <- mean(xa)
# obtain the autocovariance function
acv15 <-acf(xa, lag.max = 15, type = "covariance", plot = F)$acf

sample_m2 <- c(mean_x, acv15)

set.seed(123)
H <- 30*n
epsilon <- rnorm(H)  
eta <- rnorm(H)  
e <- cbind(epsilon,eta)

b <- 0.5
b1 <- 0.5
sig2f <- 0.1
omega <- lo(var(x))*(1-b-b1)

par_ini <- c(omega,log(b/(1-b)),log(b1/(1-b1)),log(sig2f))

# Obtain parameter estimates
# Minimize criterion function

est <- optim(par=par_ini,fn=function(par) mean((sim_m_SV3(e,par)-sample_m2)^2), method = "BFGS")

# Obtain parameter estimate using the link functions

omega_hat <- est$par[1]
beta_hat <- exp(est$par[2])/(1+exp(est$par[2]))
beta1_hat <- exp(est$par[3])/(1+exp(est$par[3]))
sig2f_hat <- exp(est$par[4])

theta_hat <- c(omega_hat,beta_hat,beta_hat1,sig2f_hat)
cat("The parameter estimates are:")
round(theta_hat,4)

# We find the following parameters: omega: 0.0774, beta0 = 0.6869 beta1 = 0.7596 sig2f = 0.1570.
